# -*- coding: utf-8 -*-
"""Human Activity Recognition

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dX-9FDb4N4xKcpD0UUwwa2YarmdIBnju
"""

import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from collections import Counter

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

from sklearn.model_selection import RandomizedSearchCV

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

train=pd.read_csv('/content/train.csv')
test=pd.read_csv('/content/test.csv')

train.info()

train.subject.value_counts()

"""**Data preprocessing**"""

print('No of dupliactes in Train :',sum(train.duplicated()))
print('No of dupliactes in Test :',sum(test.duplicated()))

print(train['Activity'].dtype)

# class imbalance
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 8))
plt.title('Barplot of Activities')

order_list = train['Activity'].value_counts().index.tolist()
sns.countplot(data=train, x='Activity', order=order_list)
plt.xticks(rotation=30)
plt.show()

"""**This represents there is no class imbalance**

**Data Analysis**
"""

train.head()

pd.DataFrame.from_dict(Counter([col.split('-')[0].split('(')[0] for col in train.columns]),orient='index')

"""**Analysing tBodyAccMag-mean feature**"""

facetgrid = sns.FacetGrid(train, hue='Activity', height=5, aspect=3)
facetgrid.map(sns.distplot, 'tBodyAccMag-mean()', hist=True).add_legend()
plt.show()

facetgrid = sns.FacetGrid(train, hue='Activity', height=5, aspect=3)
facetgrid.map(sns.distplot, 'tBodyAccMag-mean()', hist=False).add_legend()
plt.annotate('Static Activities',xy=(-0.98,8),xytext=(-0.9,15),arrowprops={'arrowstyle':'-','ls':'dashed'})
plt.annotate('Static Activities',xy=(-0.98,13.4),xytext=(-0.9,15),arrowprops={'arrowstyle':'-','ls':'dashed'})
plt.annotate('Static Activities',xy=(-0.98,16.2),xytext=(-0.9,15),arrowprops={'arrowstyle':'-','ls':'dashed'})


plt.annotate('Dynamic Activities',xy=(-0.2,3.4),xytext=(0.1,9),arrowprops={'arrowstyle':'-','ls':'dashed'})
plt.annotate('Dynamic Activities',xy=(0.1,2.2),xytext=(0.1,9),arrowprops={'arrowstyle':'-','ls':'dashed'})
plt.annotate('Dynamic Activities',xy=(-0.01,2.15),xytext=(0.1,9),arrowprops={'arrowstyle':'-','ls':'dashed'})



plt.show()

plt.figure(figsize=(12, 8))

plt.subplot(1, 2, 1)
plt.title("Static Activities (closer view)")
sns.distplot(train[train["Activity"] == "SITTING"]['tBodyAccMag-mean()'], hist=False, label='Sitting')
sns.distplot(train[train["Activity"] == "STANDING"]['tBodyAccMag-mean()'], hist=False, label='Standing')
sns.distplot(train[train["Activity"] == "LAYING"]['tBodyAccMag-mean()'], hist=False, label='Laying')
plt.axis([-1.02, -0.5, 0, 17])

plt.subplot(1, 2, 2)
plt.title("Dynamic Activities (closer view)")
sns.distplot(train[train["Activity"] == "WALKING"]['tBodyAccMag-mean()'], hist=False, label='WALKING')
sns.distplot(train[train["Activity"] == "WALKING_DOWNSTAIRS"]['tBodyAccMag-mean()'], hist=False, label='WALKING_DOWNSTAIRS')
sns.distplot(train[train["Activity"] == "WALKING_UPSTAIRS"]['tBodyAccMag-mean()'], hist=False, label='WALKING_UPSTAIRS')

plt.show()

plt.figure(figsize=(10, 7))
sns.boxplot(x="Activity", y="tBodyAccMag-mean()", data=train, showfliers=False)
plt.ylabel('Body Acceleration Magnitude mean')
plt.title("Boxplot of tBodyAccMag-mean() column across various activities")
plt.axhline(y=-0.8, xmin=0.05, dashes=(3, 3))
plt.axhline(y=0.0, xmin=0.35, dashes=(3, 3))
plt.show()

"""**Analysing Angle between X-axis and gravityMean feature**

"""

plt.figure(figsize=(10, 7))
sns.boxplot(x='Activity', y='angle(X,gravityMean)', data=train, showfliers=False)
plt.axhline(y=0.08, xmin=0.1, xmax=0.9, dashes=(3, 3))
plt.ylabel("Angle between X-axis and gravityMean")
plt.title('Box plot of angle(X,gravityMean) column across various activities')
plt.xticks(rotation=30)
plt.show()

"""**Analysing Angle between Y-axis and gravityMean feature**"""

plt.figure(figsize=(10, 7))
sns.boxplot(x='Activity', y='angle(Y,gravityMean)', data=train, showfliers=False)
plt.ylabel("Angle between Y-axis and gravityMean")
plt.title('Box plot of angle(Y,gravityMean) column across various activities')
plt.xticks(rotation=90)
plt.axhline(y=-0.35, xmin=0.01, dashes=(3, 3))
plt.show()

"""**Analysing data using PCA**"""

x_for_pca = train.drop(['subject', 'Activity'], axis=1)
pca = PCA(n_components=2, random_state=0).fit_transform(x_for_pca)
pca

plt.figure(figsize=(12, 8))
sns.scatterplot(x=pca[:, 0], y=pca[:, 1], hue=train['Activity'])
plt.show()

"""**Analysing data using tSNE**"""

x_for_tsne = train.drop(['subject', 'Activity'], axis=1)
tsne = TSNE(n_components=2, random_state=0, n_iter=1000).fit_transform(x_for_tsne)

tsne

plt.figure(figsize=(12, 12))
sns.scatterplot(x=tsne[:, 0], y=tsne[:, 1], hue=train['Activity'])
plt.show()

"""**ML MODEL**"""

X_train = train.drop(['subject', 'Activity'], axis=1)
y_train = train['Activity']

X_test = test.drop(['subject', 'Activity'], axis=1)
y_test = test['Activity']

print('Training data size : ', X_train.shape)
print('Test data size : ', X_test.shape)

"""**Logistic regression model with Hyperparameter tuning and cross validation**"""

parameters = {'max_iter': [100, 200, 500]}
lr_classifier = LogisticRegression()
lr_classifier_rs = RandomizedSearchCV(lr_classifier, param_distributions=parameters, cv=5, random_state=42)
lr_classifier_rs.fit(X_train, y_train)
y_pred_lr = lr_classifier_rs.predict(X_test)

lr_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_lr)
print("Accuracy using Logistic Regression: ", lr_accuracy)

# function to plot confusion matrix
def plot_confusion_matrix(cm, labels):
    fig, ax = plt.subplots(figsize=(12, 8))  # for plotting confusion matrix as an image
    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    ax.figure.colorbar(im, ax=ax)
    ax.set(
        xticks=np.arange(cm.shape[1]),
        yticks=np.arange(cm.shape[0]),
        xticklabels=labels, yticklabels=labels,
        ylabel='True label',
        xlabel='Predicted label'
    )
    plt.xticks(rotation=90)
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, int(cm[i, j]), ha="center", va="center", color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()

cm=confusion_matrix(y_test.values,y_pred_lr)
cm

cm=confusion_matrix(y_test.values,y_pred_lr)
plot_confusion_matrix(cm,np.unique(y_pred_lr))

# function to get best random search attributes
def get_best_randomsearch_results(model):
    print("Best estimator: ", model.best_estimator_)
    print("Best set of parameters: ", model.best_params_)
    print("Best score: ", model.best_score_)

get_best_randomsearch_results(lr_classifier_rs)

"""**SVM model with Hyperparameter tuning and cross validation**"""

parameters = {
    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],
    'C': [100, 50]
}

svm_rs = RandomizedSearchCV(SVC(), param_distributions=parameters, cv=3, random_state=42)
svm_rs.fit(X_train, y_train)

y_pred=svm_rs.predict(X_test)
y_pred

kernel_svm_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)
print("Accuracy using Kernel SVM: ", kernel_svm_accuracy)

cm=confusion_matrix(y_test.values,y_pred)
plot_confusion_matrix(cm,np.unique(y_pred))

np.unique(y_pred)

get_best_randomsearch_results(svm_rs)

"""**Decision Tree with Hyperparameter tuning and cross validation**"""

RandomizedSearchCV(
    estimator=DecisionTreeClassifier(),
    param_distributions={'max_depth': [2, 4, 6, 8]},
    random_state=42
)

parameters = {'max_depth': np.arange(2, 10, 2)}

dt_classifier = DecisionTreeClassifier()
dt_classifier_rs = RandomizedSearchCV(dt_classifier, param_distributions=parameters, random_state=42)
dt_classifier_rs.fit(X_train, y_train)

y_pred = dt_classifier_rs.predict(X_test)

dt_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)
print("Accuracy using Decision Tree: ", dt_accuracy)

cm = confusion_matrix(y_test.values, y_pred)
plot_confusion_matrix(cm, np.unique(y_pred))

get_best_randomsearch_results(dt_classifier_rs)

"""**Random forest model with Hyperparameter tuning and cross validation**"""

parameters = {
    'n_estimators': np.arange(20, 101, 10),
    'max_depth': np.arange(2, 17, 2)
}

rf_classifier = RandomForestClassifier()
rf_classifier_rs = RandomizedSearchCV(rf_classifier, param_distributions=parameters, random_state=42)
rf_classifier_rs.fit(X_train, y_train)

get_best_randomsearch_results(rf_classifier_rs)

y_pred = rf_classifier_rs.predict(X_test)

rf_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)
print("Accuracy using Random Forest: ", rf_accuracy)

cm = confusion_matrix(y_test.values, y_pred)
plot_confusion_matrix(cm, np.unique(y_pred))

